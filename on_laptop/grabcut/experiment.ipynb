{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_grabcut(img, rect) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    mask = np.zeros(img.shape[:2], np.uint8)\n",
    "    bgdModel = np.zeros((1,65),np.float64)\n",
    "    fgdModel = np.zeros((1,65),np.float64)\n",
    "    rect = (0,50,320,240-50)\n",
    "    _, bgdModel, fgdModel = cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "    return bgdModel, fgdModel, mask\n",
    "\n",
    "def overlay_bbox(img:np.ndarray, box) -> None:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    im = cv2.rectangle(img.copy(), (box[0], box[1]), (box[0] + box[2], box[1] + box[3]), color=(0,0,255), thickness=2)\n",
    "    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "def eval_grabcut(img, mask, bgdModel, fgdModel) -> np.ndarray:\n",
    "    mask, _, _= cv2.grabCut(img, mask, None, bgdModel, fgdModel, 1, cv2.GC_EVAL_FREEZE_MODEL)\n",
    "    mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "    return mask2[:,:,np.newaxis]\n",
    "\n",
    "def compare_grabcut(img, masked) -> np.ndarray:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(cv2.cvtColor(img*masked, cv2.COLOR_BGR2RGB))\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrabCutModel:\n",
    "    def __init__(self, urban_im, urban_box, rual_im, rual_box) -> None:\n",
    "        self.bgdUrban, self.fgdUrban, self.maskUrban = train_grabcut(urban_im, urban_box)\n",
    "        self.bgdRural, self.fgdRural, self.maskRural = train_grabcut(rual_im, rual_box)\n",
    "        \n",
    "    def eval_image(self, img: np.ndarray) -> np.ndarray:\n",
    "        urbanMask = eval_grabcut(img, self.maskUrban, self.bgdUrban, self.fgdUrban)\n",
    "        ruralMask = eval_grabcut(img, self.maskRural, self.bgdRural, self.fgdRural)\n",
    "        return urbanMask | ruralMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = sorted(list(Path(\"./data\").glob(\"./*.jpg\")))[100]\n",
    "print(f\"Reading {filename}\")\n",
    "rural_img = cv2.imread(str(filename))\n",
    "rural_rect = (0,50,320,240-50)\n",
    "bgdModel, fgdModel, mask = train_grabcut(rural_img, rural_rect)\n",
    "masked = eval_grabcut(rural_img, mask, bgdModel, fgdModel)\n",
    "compare_grabcut(rural_img, masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = sorted(list(Path(\"./data\").glob(\"./*.jpg\")))[300]\n",
    "print(f\"Reading {filename}\")\n",
    "urban_img = cv2.imread(str(filename))\n",
    "urban_rect = (0,50,320,240-50)\n",
    "bgdModel, fgdModel, mask = train_grabcut(urban_img, urban_rect)\n",
    "masked = eval_grabcut(urban_img, mask, bgdModel, fgdModel)\n",
    "compare_grabcut(urban_img, masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = sorted(list(Path(\"./data\").glob(\"./*.jpg\")))[150]\n",
    "print(f\"Reading {filename}\")\n",
    "scene = \"rural\"\n",
    "assert scene in {\"rural\", \"urban\"}\n",
    "img = cv2.imread(str(filename))\n",
    "rect = (0,130,320,240-130)\n",
    "overlay_bbox(img, rect)\n",
    "bgdModel, fgdModel, mask = train_grabcut(img, rect)\n",
    "masked = eval_grabcut(img, mask, bgdModel, fgdModel)\n",
    "compare_grabcut(img, masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "db_file = Path(\"grabcut_anns.yml\")\n",
    "if not db_file.exists():\n",
    "    with open(db_file, \"w\") as f:\n",
    "        yaml.safe_dump({\"rural\": {}, \"urban\": {}}, f)\n",
    "\n",
    "with open(db_file, \"r\") as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "data[scene][str(filename)] = rect\n",
    "\n",
    "with open(db_file, \"w\") as f:\n",
    "    yaml.safe_dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_bbox(urban_img, urban_rect)\n",
    "overlay_bbox(rural_img, rural_rect)\n",
    "model = GrabCutModel(urban_img, urban_rect, rural_img, rural_rect)\n",
    "masked = model.eval_image(urban_img)\n",
    "compare_grabcut(urban_img, masked)\n",
    "masked = model.eval_image(rural_img)\n",
    "compare_grabcut(rural_img, masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = sorted(list(Path(\"./data\").glob(\"./*.jpg\")))[130]\n",
    "# print(f\"Reading {filename}\")\n",
    "# img2 = cv2.imread(str(filename))\n",
    "# masked = model.eval_image(img2)\n",
    "# compare_grabcut(img2, masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "writer = cv2.VideoWriter(\"grabcut.avi\", fourcc, 10.0, (320, 240))\n",
    "\n",
    "for file_ in tqdm(sorted(list(Path(\"./data\").glob(\"./*.jpg\")))):\n",
    "    img = cv2.imread(str(file_))\n",
    "    masked = model.eval_image(img)\n",
    "    writer.write(img * masked)\n",
    "    # compare_grabcut(img, masked)\n",
    "    # plt.show()\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "# dy = cv2.Sobel(grey, cv2.CV_8U, 0, 1)\n",
    "# dx = cv2.Sobel(grey, cv2.CV_8U, 1, 0)\n",
    "grad=cv2.Laplacian(grey, cv2.CV_8U)\n",
    "plt.imshow(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones(img.shape[:-1], dtype=bool)\n",
    "hsv_im = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# define range of blue color in HSV\n",
    "lower_blue = np.array([0,0,50])\n",
    "upper_blue = np.array([255,10,255])\n",
    "# Threshold the HSV image to get only blue colors\n",
    "mask = cv2.inRange(hsv_im, lower_blue, upper_blue)\n",
    "hsv_im = hsv_im.astype(np.float32)\n",
    "grad=cv2.Laplacian(hsv_im[..., 1] * hsv_im[..., 2], cv2.CV_32F)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(grad)\n",
    "plt.subplot(122)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones(img.shape[:-1], dtype=bool)\n",
    "hsv_im = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# define range of blue color in HSV\n",
    "lower_blue = np.array([0,0,0])\n",
    "upper_blue = np.array([255,100,90])\n",
    "# Threshold the HSV image to get only blue colors\n",
    "mask = cv2.inRange(hsv_im, lower_blue, upper_blue)\n",
    "hsv_im = hsv_im.astype(np.float32)\n",
    "grad=cv2.Laplacian(hsv_im[..., 1] * hsv_im[..., 2], cv2.CV_32F)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(mask)\n",
    "plt.subplot(122)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "print(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)[128,128])\n",
    "print(hsv_im[128,128])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
